{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold\n",
    "#KFold\n",
    "#https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "plt.style.use('ggplot') # Look Pretty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('train_values.csv', index_col='row_id')\n",
    "y = pd.read_csv('train_labels.csv', index_col='row_id')\n",
    "df_predict = pd.read_csv('test_values.csv', index_col='row_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check unique value for each column\n",
    "def unique_counts(df):\n",
    "    for i in df.columns:\n",
    "        count = df[i].nunique()\n",
    "        print(i, \": \", count)\n",
    "        \n",
    "unique_counts(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Correction list and categorical list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_list(df, y):\n",
    "    corr_list = []\n",
    "    categorical_list = []\n",
    "    numeric_count = 0\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if np.issubdtype(df[col].dtype, np.number):\n",
    "            corr = (col, y[y.columns[0]].corr(X[col]))\n",
    "            #print(col, \": \", corr)\n",
    "            corr_list.append(corr)\n",
    "        \n",
    "            numeric_count += 1\n",
    "            min_val = df[col].min()\n",
    "            max_val = df[col].max()\n",
    "            print(numeric_count, col, '\\n Min:', min_val,'Max:', max_val, '\\n')\n",
    "        \n",
    "        else:\n",
    "            categorical_list.append(col)\n",
    "            \n",
    "    return corr_list, categorical_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 econ__pct_civilian_labor \n",
      " Min: 0.207 Max: 1.0 \n",
      "\n",
      "2 econ__pct_unemployment \n",
      " Min: 0.01 Max: 0.248 \n",
      "\n",
      "3 econ__pct_uninsured_adults \n",
      " Min: 0.046 Max: 0.496 \n",
      "\n",
      "4 econ__pct_uninsured_children \n",
      " Min: 0.012 Max: 0.281 \n",
      "\n",
      "5 demo__pct_female \n",
      " Min: 0.278 Max: 0.573 \n",
      "\n",
      "6 demo__pct_below_18_years_of_age \n",
      " Min: 0.092 Max: 0.41700000000000004 \n",
      "\n",
      "7 demo__pct_aged_65_years_and_older \n",
      " Min: 0.045 Max: 0.34600000000000003 \n",
      "\n",
      "8 demo__pct_hispanic \n",
      " Min: 0.0 Max: 0.932 \n",
      "\n",
      "9 demo__pct_non_hispanic_african_american \n",
      " Min: 0.0 Max: 0.858 \n",
      "\n",
      "10 demo__pct_non_hispanic_white \n",
      " Min: 0.053 Max: 0.99 \n",
      "\n",
      "11 demo__pct_american_indian_or_alaskan_native \n",
      " Min: 0.0 Max: 0.8590000000000001 \n",
      "\n",
      "12 demo__pct_asian \n",
      " Min: 0.0 Max: 0.341 \n",
      "\n",
      "13 demo__pct_adults_less_than_a_high_school_diploma \n",
      " Min: 0.01507537688442211 Max: 0.4735264735264735 \n",
      "\n",
      "14 demo__pct_adults_with_high_school_diploma \n",
      " Min: 0.06532663316582914 Max: 0.5589123867069486 \n",
      "\n",
      "15 demo__pct_adults_with_some_college \n",
      " Min: 0.10954773869346733 Max: 0.47395301327885603 \n",
      "\n",
      "16 demo__pct_adults_bachelors_or_higher \n",
      " Min: 0.01107754279959718 Max: 0.7989949748743718 \n",
      "\n",
      "17 demo__birth_rate_per_1k \n",
      " Min: 4.0 Max: 29.0 \n",
      "\n",
      "18 demo__death_rate_per_1k \n",
      " Min: 0.0 Max: 27.0 \n",
      "\n",
      "19 health__pct_adult_obesity \n",
      " Min: 0.131 Max: 0.47100000000000003 \n",
      "\n",
      "20 health__pct_adult_smoking \n",
      " Min: 0.046 Max: 0.513 \n",
      "\n",
      "21 health__pct_diabetes \n",
      " Min: 0.032 Max: 0.203 \n",
      "\n",
      "22 health__pct_low_birthweight \n",
      " Min: 0.033 Max: 0.23800000000000002 \n",
      "\n",
      "23 health__pct_excessive_drinking \n",
      " Min: 0.038 Max: 0.36700000000000005 \n",
      "\n",
      "24 health__pct_physical_inacticity \n",
      " Min: 0.09 Max: 0.442 \n",
      "\n",
      "25 health__air_pollution_particulate_matter \n",
      " Min: 7.0 Max: 15.0 \n",
      "\n",
      "26 health__homicides_per_100k \n",
      " Min: -0.4 Max: 50.49 \n",
      "\n",
      "27 health__motor_vehicle_crash_deaths_per_100k \n",
      " Min: 3.14 Max: 110.45 \n",
      "\n",
      "28 health__pop_per_dentist \n",
      " Min: 339.0 Max: 28130.0 \n",
      "\n",
      "29 health__pop_per_primary_care_physician \n",
      " Min: 189.0 Max: 23399.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "corr_list, X_cat_list = create_list(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print unique value for catergorical columns\n",
    "for i in X_cat_list:\n",
    "    value = X[i].unique()\n",
    "    print(i, \": \", value,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph plotting for catergorical columns\n",
    "for col in X_cat_list:\n",
    "    X[col].value_counts().plot(kind='bar')\n",
    "    plt.title(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking corelation of catergorical columns and y label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('demo__pct_adults_less_than_a_high_school_diploma', 0.5273816184439839)\n",
      "('demo__pct_adults_bachelors_or_higher', -0.5413849922585271)\n",
      "('health__pct_adult_obesity', 0.5937750422550884)\n",
      "('health__pct_diabetes', 0.631765016185405)\n",
      "('health__pct_physical_inacticity', 0.6503046257575985)\n"
     ]
    }
   ],
   "source": [
    "#select feature with significant correlation with rate of heart disease\n",
    "corr_rate = 0.5\n",
    "corr_plot_list = []\n",
    "for feature in corr_list:\n",
    "    if abs(feature[1]) > corr_rate:\n",
    "        print(feature)\n",
    "        corr_plot_list.append(feature[0])\n",
    "#sorted(corr_list, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create df for scatter plot\n",
    "df_scatter = pd.concat([X[corr_plot_list],y], axis=1)\n",
    "df_scatter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scatter.columns = [\n",
    "    'Does not have a high school diploma',\n",
    "    'Bachelor\\'s degree or higher',\n",
    "    'Adults who obese',\n",
    "    'Population with diabetes',\n",
    "    'Adult that is physically inactive',\n",
    "    'Rate of heart disease'\n",
    "]\n",
    "pd.plotting.scatter_matrix(df_scatter, alpha = 0.2, figsize = (18, 18), diagonal = 'kde')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take log to 'Rate of heart disease'\n",
    "df_scatter['ln_Rate of heart disease'] = np.log(df_scatter['Rate of heart disease']+1)\n",
    "pd.plotting.scatter_matrix(df_scatter.drop(['Rate of heart disease'], axis=1), alpha = 0.2, figsize = (18, 18), diagonal = 'kde')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scatter.drop(['Rate of heart disease'], axis=1).corr()#.to_csv('corr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Box plot\n",
    "def create_boxplot(X,y):\n",
    "    df = pd.concat([X,y], axis=1)\n",
    "    for col in X_cat_list:\n",
    "        df.boxplot(column=y.columns[0], by=col, figsize = (20, 10))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_boxplot(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of y label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y['heart_disease_mortality_per_100k'].plot.hist(alpha=0.5)\n",
    "plt.title('Rate of heart disease (per 100,000 individuals)')\n",
    "plt.xlabel('Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check median values by area__rucc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>health__pct_adult_smoking</th>\n",
       "      <th>health__pct_low_birthweight</th>\n",
       "      <th>health__pct_excessive_drinking</th>\n",
       "      <th>health__air_pollution_particulate_matter</th>\n",
       "      <th>health__motor_vehicle_crash_deaths_per_100k</th>\n",
       "      <th>health__pop_per_dentist</th>\n",
       "      <th>health__pop_per_primary_care_physician</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metro?</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Metro</th>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.165</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.06</td>\n",
       "      <td>2179.0</td>\n",
       "      <td>1769.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nonmetro</th>\n",
       "      <td>0.2165</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.162</td>\n",
       "      <td>12.0</td>\n",
       "      <td>22.84</td>\n",
       "      <td>2940.0</td>\n",
       "      <td>2104.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          health__pct_adult_smoking  health__pct_low_birthweight  \\\n",
       "Metro?                                                             \n",
       "Metro                        0.1980                        0.080   \n",
       "Nonmetro                     0.2165                        0.081   \n",
       "\n",
       "          health__pct_excessive_drinking  \\\n",
       "Metro?                                     \n",
       "Metro                              0.165   \n",
       "Nonmetro                           0.162   \n",
       "\n",
       "          health__air_pollution_particulate_matter  \\\n",
       "Metro?                                               \n",
       "Metro                                         12.0   \n",
       "Nonmetro                                      12.0   \n",
       "\n",
       "          health__motor_vehicle_crash_deaths_per_100k  \\\n",
       "Metro?                                                  \n",
       "Metro                                           14.06   \n",
       "Nonmetro                                        22.84   \n",
       "\n",
       "          health__pop_per_dentist  health__pop_per_primary_care_physician  \n",
       "Metro?                                                                     \n",
       "Metro                      2179.0                                  1769.5  \n",
       "Nonmetro                   2940.0                                  2104.5  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_metro = X.copy()\n",
    "df_X_metro['Metro?'] = 'Nonmetro'\n",
    "df_X_metro.loc[X['area__rucc'].str[:5] == 'Metro', 'Metro?']= 'Metro'\n",
    "\n",
    "na_list = ['health__pct_adult_smoking', \n",
    "           'health__pct_low_birthweight',\n",
    "           'health__pct_excessive_drinking', #\n",
    "           'health__air_pollution_particulate_matter',\n",
    "           'health__motor_vehicle_crash_deaths_per_100k', #median()\n",
    "           'health__pop_per_dentist', #median()\n",
    "           'health__pop_per_primary_care_physician' #median()\n",
    "          ] \n",
    "\n",
    "#df_X_metro.groupby('Metro?')[na_list].mean()\n",
    "df_X_metro.groupby('Metro?')[na_list].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_metro.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_metro.boxplot(column='health__homicides_per_100k', by='area__rucc', figsize = (20, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['area__rucc', 'area__urban_influence', 'econ__economic_typology', 'yr']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>health__pct_adult_smoking</th>\n",
       "      <th>health__pct_low_birthweight</th>\n",
       "      <th>health__pct_excessive_drinking</th>\n",
       "      <th>health__air_pollution_particulate_matter</th>\n",
       "      <th>health__motor_vehicle_crash_deaths_per_100k</th>\n",
       "      <th>health__pop_per_dentist</th>\n",
       "      <th>health__pop_per_primary_care_physician</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>econ__economic_typology</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Farm-dependent</th>\n",
       "      <td>0.1830</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.1935</td>\n",
       "      <td>11.0</td>\n",
       "      <td>26.305</td>\n",
       "      <td>3089.0</td>\n",
       "      <td>2289.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Federal/State government-dependent</th>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.1595</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.300</td>\n",
       "      <td>2480.0</td>\n",
       "      <td>1914.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manufacturing-dependent</th>\n",
       "      <td>0.2190</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.1540</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.580</td>\n",
       "      <td>3270.0</td>\n",
       "      <td>2219.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mining-dependent</th>\n",
       "      <td>0.2235</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.1530</td>\n",
       "      <td>10.0</td>\n",
       "      <td>26.290</td>\n",
       "      <td>3215.0</td>\n",
       "      <td>2319.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nonspecialized</th>\n",
       "      <td>0.2130</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.1560</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.040</td>\n",
       "      <td>2519.0</td>\n",
       "      <td>1879.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recreation</th>\n",
       "      <td>0.1990</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.1790</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.830</td>\n",
       "      <td>2255.0</td>\n",
       "      <td>1619.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    health__pct_adult_smoking  \\\n",
       "econ__economic_typology                                         \n",
       "Farm-dependent                                         0.1830   \n",
       "Federal/State government-dependent                     0.2030   \n",
       "Manufacturing-dependent                                0.2190   \n",
       "Mining-dependent                                       0.2235   \n",
       "Nonspecialized                                         0.2130   \n",
       "Recreation                                             0.1990   \n",
       "\n",
       "                                    health__pct_low_birthweight  \\\n",
       "econ__economic_typology                                           \n",
       "Farm-dependent                                            0.073   \n",
       "Federal/State government-dependent                        0.083   \n",
       "Manufacturing-dependent                                   0.080   \n",
       "Mining-dependent                                          0.085   \n",
       "Nonspecialized                                            0.083   \n",
       "Recreation                                                0.072   \n",
       "\n",
       "                                    health__pct_excessive_drinking  \\\n",
       "econ__economic_typology                                              \n",
       "Farm-dependent                                              0.1935   \n",
       "Federal/State government-dependent                          0.1595   \n",
       "Manufacturing-dependent                                     0.1540   \n",
       "Mining-dependent                                            0.1530   \n",
       "Nonspecialized                                              0.1560   \n",
       "Recreation                                                  0.1790   \n",
       "\n",
       "                                    health__air_pollution_particulate_matter  \\\n",
       "econ__economic_typology                                                        \n",
       "Farm-dependent                                                          11.0   \n",
       "Federal/State government-dependent                                      12.0   \n",
       "Manufacturing-dependent                                                 13.0   \n",
       "Mining-dependent                                                        10.0   \n",
       "Nonspecialized                                                          12.0   \n",
       "Recreation                                                              11.0   \n",
       "\n",
       "                                    health__motor_vehicle_crash_deaths_per_100k  \\\n",
       "econ__economic_typology                                                           \n",
       "Farm-dependent                                                           26.305   \n",
       "Federal/State government-dependent                                       17.300   \n",
       "Manufacturing-dependent                                                  20.580   \n",
       "Mining-dependent                                                         26.290   \n",
       "Nonspecialized                                                           18.040   \n",
       "Recreation                                                               16.830   \n",
       "\n",
       "                                    health__pop_per_dentist  \\\n",
       "econ__economic_typology                                       \n",
       "Farm-dependent                                       3089.0   \n",
       "Federal/State government-dependent                   2480.0   \n",
       "Manufacturing-dependent                              3270.0   \n",
       "Mining-dependent                                     3215.0   \n",
       "Nonspecialized                                       2519.0   \n",
       "Recreation                                           2255.0   \n",
       "\n",
       "                                    health__pop_per_primary_care_physician  \n",
       "econ__economic_typology                                                     \n",
       "Farm-dependent                                                      2289.0  \n",
       "Federal/State government-dependent                                  1914.0  \n",
       "Manufacturing-dependent                                             2219.5  \n",
       "Mining-dependent                                                    2319.0  \n",
       "Nonspecialized                                                      1879.0  \n",
       "Recreation                                                          1619.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#median by categorical_list\n",
    "X.groupby('econ__economic_typology')[na_list].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove columns/ rows and Replace NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(['health__homicides_per_100k'], axis=1, inplace=True)\n",
    "#Require at least 20/33 non-NA values\n",
    "#X.dropna(thresh=20, inplace=True)\n",
    "#fill na with mean\n",
    "#X.fillna(X.median(), inplace=True)\n",
    "#fill na with group median\n",
    "X.fillna(X.groupby(X_cat_list).transform('median'), inplace=True)\n",
    "X['health__air_pollution_particulate_matter']=X['health__air_pollution_particulate_matter'].astype(str)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict.drop(['health__homicides_per_100k'], axis=1, inplace=True)\n",
    "\n",
    "#fill na with group median\n",
    "df_predict.fillna(df_predict.groupby(X_cat_list).transform('median'), inplace=True)\n",
    "df_predict['health__air_pollution_particulate_matter']=df_predict['health__air_pollution_particulate_matter'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take log and check min, max for numeric columns, put catergorical column name to cat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_transform(df):\n",
    "    count = 0\n",
    "    for col in df.columns:       \n",
    "        if np.issubdtype(df[col].dtype, np.number):\n",
    "            count += 1\n",
    "            print(count,'.Updating column:',col)\n",
    "            df[col] = np.log(df[col]+1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_transform(X)\n",
    "df_predict = data_transform(df_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ind(df, indicator, diagonal_type):\n",
    "    df_filtered = df.filter(regex=indicator)\n",
    "    pd.plotting.scatter_matrix(df_filtered, alpha = 0.2, figsize = (20, 20), diagonal = diagonal_type)\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ind(X, 'econ__pct','kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_ind(X, 'demo__','kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ind(X, 'health__','kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot, Train_Test Split and Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(df, cat_list):\n",
    "    return pd.get_dummies(df, columns = cat_list) #get_dummies as Onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_dummies as Onehot\n",
    "X = one_hot(X, X_cat_list)\n",
    "df_predict = one_hot(df_predict, X_cat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train:Test = 80:20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y.values.ravel(), train_size =0.80, test_size = 0.2, random_state=154)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature scaling\n",
    "std_scale = StandardScaler().fit(X_train)\n",
    "\n",
    "X_train_std = std_scale.transform(X_train)\n",
    "X_test_std = std_scale.transform(X_test)\n",
    "\n",
    "X_predict_std = std_scale.transform(df_predict)\n",
    "\n",
    "#set cv by K-Fold\n",
    "kf = KFold(n_splits=30, shuffle=True, random_state=52)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########Baseline case only##########\n",
    "print('##########Baseline Model##########')\n",
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(X_train_std , y_train)\n",
    "\n",
    "lr_train_scores = cross_val_score(lr, X_train_std, y_train, scoring='neg_mean_squared_error', cv=kf)\n",
    "lr_test_scores = cross_val_score(lr, X_test_std, y_test, scoring='neg_mean_squared_error', cv=kf)\n",
    "\n",
    "print('RMSE for Train set: %.2f' % abs(lr_train_scores.mean())**(1/2))\n",
    "print('RMSE for Test set: %.2f' % abs(lr_test_scores.mean())**(1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding best parameter for model\n",
    "def find_best_params(model_name, grid_values):\n",
    "    model = model_name\n",
    "    grid_search = GridSearchCV(estimator = model, param_grid = grid_values, scoring='neg_mean_squared_error')\n",
    "    # Fit the grid search to the data\n",
    "    grid_search.fit(X_train_std, y_train)\n",
    "    \n",
    "    grid_search_scores = cross_val_score(grid_search, X_train_std, y_train, cv=kf, scoring='neg_mean_squared_error')\n",
    "\n",
    "    print('Grid best parameter: ', grid_search.best_params_)\n",
    "    print('Best score: %.2f' % abs(grid_search.best_score_)**(1/2))\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (abs(grid_search_scores.mean())**(1/2), grid_search_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_values = {'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 20, 25, 30, 50]}\n",
    "model_name = linear_model.Ridge()\n",
    "\n",
    "find_best_params(model_name, grid_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('##########Ridge Regression Test Set Result##########')\n",
    "\n",
    "ridge_lr = linear_model.Ridge(alpha=10)\n",
    "ridge_lr_train_scores = cross_val_score(ridge_lr, X_train_std, y_train, scoring='neg_mean_squared_error', cv=kf)\n",
    "ridge_lr_test_scores = cross_val_score(ridge_lr, X_test_std, y_test, scoring='neg_mean_squared_error', cv=kf)\n",
    "\n",
    "print('RMSE for Train set: %.2f' % abs(ridge_lr_train_scores.mean())**(1/2))\n",
    "print('RMSE for Test set: %.2f' % abs(ridge_lr_test_scores.mean())**(1/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "print('##########Lasso##########')\n",
    "lassocv_lr = linear_model.LassoCV()\n",
    "lassocv_lr.fit(X_train_std , y_train)\n",
    "\n",
    "#y_cv_lassocv_lr = lassocv_lr.predict(X_cv_std)\n",
    "#print('RMSE for CV set: %.2f' %(mean_squared_error(y_cv, y_cv_lassocv_lr))** (1/2))\n",
    "\n",
    "#########After best parameter is selected#########\n",
    "#y_test_lassocv_lr = lassocv_lr.predict(X_test_std)\n",
    "#print('RMSE for test set: %.2f' %(mean_squared_error(y_test, y_test_lassocv_lr))** (1/2))\n",
    "\n",
    "lassocv_lr_scores = cross_val_score(lassocv_lr, X_train, y_train, cv=30, scoring='neg_mean_squared_error')\n",
    "\n",
    "print('RMSE for Train set: %.2f' % abs(lassocv_lr_scores.mean())**(1/2))\n",
    "print('RMSE for Test set:')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_values = {'alpha': [0.01, 0.02, 0.03, 0.05, 0.1, 1, 10], 'max_iter':[10000,5000]}\n",
    "\n",
    "model_name = linear_model.Lasso()\n",
    "find_best_params(model_name, grid_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('##########Lasso Regression Test Set Result##########')\n",
    "\n",
    "lasso_lr = linear_model.Lasso(alpha=0.05, max_iter=10000)\n",
    "lasso_lr_train_scores = cross_val_score(lasso_lr, X_train_std, y_train, scoring='neg_mean_squared_error', cv=kf)\n",
    "lasso_lr_test_scores = cross_val_score(lasso_lr, X_test_std, y_test, scoring='neg_mean_squared_error', cv=kf)\n",
    "\n",
    "print('RMSE for Train set: %.2f' % abs(lasso_lr_train_scores.mean())**(1/2))\n",
    "print('RMSE for Test set: %.2f' % abs(lasso_lr_test_scores.mean())**(1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_values = {'alpha': [0.01, 0.02, 0.03, 0.05, 0.1, 1, 10], 'l1_ratio': [0.1, 0.5, 0.7, 0.9, 1]}\n",
    "\n",
    "model_name = linear_model.ElasticNet()\n",
    "find_best_params(model_name, grid_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('##########ElasticNet Test Set Result##########')\n",
    "\n",
    "en = linear_model.ElasticNet(alpha=0.02, l1_ratio=0.9)\n",
    "en_train_scores = cross_val_score(en, X_train_std, y_train, scoring='neg_mean_squared_error', cv=kf)\n",
    "en_test_scores = cross_val_score(en, X_test_std, y_test, scoring='neg_mean_squared_error', cv=kf)\n",
    "\n",
    "print('RMSE for Train set: %.2f' % abs(en_train_scores.mean())**(1/2))\n",
    "print('RMSE for Test set: %.2f' % abs(en_test_scores.mean())**(1/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model):\n",
    "    \n",
    "    #create dataframe for answer\n",
    "    df = pd.DataFrame(df_predict.index)\n",
    "\n",
    "    model.fit(X_train_std, y_train)\n",
    "\n",
    "    #return the result of predict\n",
    "    df['heart_disease_mortality_per_100k'] = pd.Series(model.predict(X_predict_std))\n",
    "    df['heart_disease_mortality_per_100k'] =df['heart_disease_mortality_per_100k'].astype('int')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = prediction(linear_model.Ridge(alpha=10)) #32.1999\n",
    "#df = prediction(linear_model.Lasso(alpha=0.05)) #32.1632 #32.1086 by group median\n",
    "#df = prediction(linear_model.LinearRegression()) #32.2258\n",
    "#df = prediction(RandomForestRegressor(bootstrap=True, max_depth=15, max_features=20, min_samples_leaf=3, min_samples_split=3)) #35.7147\n",
    "\n",
    "df.to_csv('test_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_values = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [15, 20, 25],\n",
    "    'max_features': [10, 15, 20],\n",
    "    'min_samples_leaf': [3, 5, 8],\n",
    "    'min_samples_split': [3, 5, 8],\n",
    "}\n",
    "model_name = RandomForestRegressor()\n",
    "find_best_params(model_name, grid_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_estimators, max_features, max_depth, min_samples_split \n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "print('##########Random Forest Test Set Result##########')\n",
    "\n",
    "rf = RandomForestRegressor(bootstrap=True, max_depth=15, max_features=20, min_samples_leaf=3, min_samples_split=3)\n",
    "rf_train_scores = cross_val_score(rf, X_train_std, y_train, scoring='neg_mean_squared_error', cv=kf)\n",
    "rf_test_scores = cross_val_score(rf, X_test_std, y_test, scoring='neg_mean_squared_error', cv=kf)\n",
    "\n",
    "print('RMSE for Train set: %.2f' % abs(rf_train_scores.mean())**(1/2))\n",
    "print('RMSE for Test set: %.2f' % abs(rf_test_scores.mean())**(1/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train_std, y_train)\n",
    "df_feature = pd.DataFrame(X.columns, columns=['feature'])\n",
    "\n",
    "#return the result of predict\n",
    "df_feature['feature_importances'] = pd.Series(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_importances of catergorical features\n",
    "cat_list = ['area__rucc', 'area__urban_influence', 'econ__economic_typology', 'health__air_pollution_particulate_matter', 'yr']\n",
    "df_feature[df_feature['feature'].isin(cat_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 10 features\n",
    "df_feature.sort_values(by=['feature_importances'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/42228735/scikit-learn-gridsearchcv-with-multiple-repetitions/42230764#42230764\n",
    "#https://stackoverflow.com/questions/42362027/model-help-using-scikit-learn-when-using-gridsearch/42364900#42364900\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=52)\n",
    "gcv = GridSearchCV(pipe, param_grid = grid_values, cv=cv)\n",
    "\n",
    "gcv.fit(features,labels) #with the full dataset\n",
    "\n",
    "for train_ind, test_ind in cv.split(features,labels):\n",
    "    x_train, x_test = features[train_ind], features[test_ind]\n",
    "    y_train, y_test = labels[train_ind],labels[test_ind]\n",
    "\n",
    "    gcv.best_estimator_.fit(x_train,y_train)\n",
    "    gcv.best_estimator_.predict(x_test)\n",
    "#################################################################    \n",
    "for train_index, test_index in kf.split(X):\n",
    "...    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "...    X_train, X_test = X[train_index], X[test_index]\n",
    "...    y_train, y_test = y[train_index], y[test_index]\n",
    "TRAIN: [2 3] TEST: [0 1]\n",
    "TRAIN: [0 1] TEST: [2 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=30, shuffle=True, random_state=52)\n",
    "for train_index, test_index in kf.split(X,y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############Test#################\n",
    "#std_scale = StandardScaler().fit(X)\n",
    "\n",
    "grid_values = {'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=52)\n",
    "gcv = GridSearchCV(ridge_lr, param_grid = grid_values, cv=cv)\n",
    "\n",
    "#gcv.fit(features,labels) #with the full dataset\n",
    "gcv.fit(X, y)\n",
    "\n",
    "for train_ind, test_ind in cv.split(X, y):\n",
    "    x_train, x_test = X[train_ind], X[test_ind]\n",
    "    y_train, y_test = y[train_ind],y[test_ind]\n",
    "\n",
    "    gcv.best_estimator_.fit(x_train,y_train)\n",
    "    gcv.best_estimator_.predict(x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
